# -*- coding: utf-8 -*-
"""Untitled12.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/112PeD1HYcUwBg0V0WLumhQaD9IGaXFpB
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import os
from matplotlib import rcParams
import warnings

warnings.filterwarnings(action='ignore')
warnings.warn('This is a warning!')

data = pd.read_csv('C:\Water Quality PRediction\water_dataX.csv',encoding= 'unicode_escape')

data.head()

data.describe()

data.info()

data.shape

"""Missing Values"""

data.isnull().any()

data.isnull().sum()

data.dtypes

data['Temp'] = pd.to_numeric(data['Temp'], errors='coerce')
data['D.O. (mg/l)'] = pd.to_numeric(data['D.O. (mg/l)'], errors='coerce')
data['PH'] = pd.to_numeric(data['PH'], errors='coerce')
data['B.O.D. (mg/l)'] = pd.to_numeric(data['B.O.D. (mg/l)'], errors='coerce')
data['CONDUCTIVITY (µmhos/cm)'] = pd.to_numeric(data['CONDUCTIVITY (µmhos/cm)'], errors='coerce')
data['NITRATENAN N+ NITRITENANN (mg/l)'] = pd.to_numeric(data['NITRATENAN N+ NITRITENANN (mg/l)'], errors='coerce')
data['TOTAL COLIFORM (MPN/100ml)Mean'] = pd.to_numeric(data['TOTAL COLIFORM (MPN/100ml)Mean'], errors='coerce')

data.dtypes

data['Temp'].fillna(data['Temp'].mean(), inplace=True)
data['D.O. (mg/l)']. fillna(data['D.O. (mg/l)'].mean(), inplace=True)
data['PH'].fillna(data['PH'].mean(), inplace=True)
data['CONDUCTIVITY (µmhos/cm)'].fillna (data['CONDUCTIVITY (µmhos/cm)'].mean(), inplace=True)
data['B.O.D. (mg/l)'].fillna (data['B.O.D. (mg/l)'].mean(), inplace=True)
data['NITRATENAN N+ NITRITENANN (mg/l)'].fillna(data['NITRATENAN N+ NITRITENANN (mg/l)'].mean(), inplace=True)
data['TOTAL COLIFORM (MPN/100ml)Mean'].fillna (data['TOTAL COLIFORM (MPN/100ml)Mean'].mean(), inplace=True)
data.drop(["FECAL COLIFORM (MPN/100ml)"], axis=1, inplace=True)

"""Renaming the Column Names"""

data = data.rename(columns={'D.O. (mg/l)': 'do'})
data = data.rename(columns={'CONDUCTIVITY (µmhos/cm)': 'co'})
data = data.rename(columns={'B.O.D. (mg/l)': 'bod'})
data = data.rename(columns={'NITRATENAN N+ NITRITENANN (mg/l)': 'na'})
data = data.rename(columns={'TOTAL COLIFORM (MPN/100ml)Mean': 'tc'})
data = data.rename(columns={'STATION CODE': 'station'})
data = data.rename(columns={'LOCATIONS': 'location'})
data = data.rename(columns={'STATE': 'state'})
data = data.rename(columns={'PH': 'ph'})

data

"""Claculation of pH"""

data['npH']=data.ph.apply(lambda x: (100 if(8.5>=x>=7)
else (80 if(8.6>=x>=8.5) or (6.9>=x>=6.8)
else (60 if(8.8>=x>=8.6) or (6.8>=x>=6.7)
else (40 if(9>=x>=8.8) or (6.7>=x>=6.5)
else 0)))))

"""calculation of dissolved oxygen"""

data['ndo']=data.do.apply(lambda x: (100 if(x>=6)
else (80 if(6>=x>=5.1)
else (60 if(5>=x>=4.1)
else (40 if(4>=x>=3)
else 0)))))

"""calculation of total coliform"""

data['nco']=data.tc.apply(lambda x: (100 if(5>=x>=0)
else (80 if(50>=x>=5)
else (60 if(500>=x>=50)
else (40 if(10000>=x>=500)
else 0)))))

"""calculation of B.D.O"""

data['nbdo']=data.bod.apply(lambda x: (100 if(3>=x>=0)
else (80 if(6>=x>=3)
else (60 if(80>=x>=6)
else (40 if(125>=x>=80)
else 0)))))

"""calculation of electric conductivity"""

data['nec']=data.co.apply(lambda x: (100 if(75>=x>=0)
else (80 if (150>=x>=75)
else (60 if(225>=x>=150)
else (40 if(300>=x>=225)
else 0)))))

"""calculation of nitrate"""

data['nna']=data.na.apply(lambda x: (100 if(20>=x>=0)
else (80 if(50>=x>=20)
else (60 if (100>=x>=50)
else (40 if(200>=x>=100)
else 0)))))

"""Calculation of Water Quality Index WQI"""

data['wph']=data.npH*0.165
data['wdo']=data.ndo*0.281
data['wbdo']=data.nbdo*0.234
data['wec']=data.nec*0.009
data['wna']=data.nna*0.028
data['wco']=data.nco*0.281
data['wqi']=data.wph+data.wdo+data.wbdo+data.wec+data.wna+data.wco
data

"""Calculation of overall WQI for each year"""

average = data.groupby( 'year') ['wqi'].mean()
average.head()

"""Data Visualization"""

sns.displot(data. Temp)
plt.show()

sns.displot(data. do)
plt.show()

sns.displot(data. bod)
plt.show()

sns.displot(data. na)
plt.show()

sns.displot(data. year)
plt.show()

sns.countplot(data.ph)
plt.show()

sns.distplot(data.npH)
plt.show()

sns.distplot(data.nco)
plt.show()

sns.distplot(data.nec)
plt.show()

"""pie chart"""

plt.pie(data.year.value_counts (), [0.1,0,0,0,0,0,0,0,0,0,0,0], labels=[2012, 2013, 2014, 2011, 2010, 2009, 2008, 2007, 2005, 2006, 2003, 2004 ], autopct='%1.1f%%')
plt.title('YEAR')
plt.show()

plt.pie(data.wph.value_counts (), [0,0.2,0,0,0], labels=[16.5,0.0,13.2,6.6,9.9], autopct='%1.1f%%')
plt.title( 'wph')
plt.show()

"""Bivariate analysis

Line plot
"""

sns.lineplot(data=data, x='ph', y='do')
plt.show()

sns.lineplot(data=data, x='co', y='bod')
plt.show()

sns.lineplot(data=data, x='na', y='tc')
plt.show()

sns.lineplot(data=data, x='npH', y='ndo')
plt.show()

sns.lineplot(data=data, x='nco', y='nbdo')
plt.show()

sns.lineplot(data=data, x='wna', y='wco')
plt.show()

"""Scatter Plot"""

sns.scatterplot(data=data, x='ph', y='bod')
plt.show()

sns.scatterplot(data=data, x='co', y='do')
plt.show()

sns.scatterplot(data=data, x='bod', y='na')
plt.show()

sns.scatterplot(data=data, x='co', y='tc')
plt.show()

sns.scatterplot(data=data, x='npH', y='nbdo')
plt.show()

sns.scatterplot(data=data, x='nco', y='ndo')
plt.show()

sns.scatterplot(data=data, x='nco', y='nna')
plt.show()

sns.scatterplot(data=data, x='nbdo', y='nec')
plt.show()

sns.scatterplot(data=data, x='wph', y='wec')
plt.show()

sns.scatterplot(data=data, x='wdo', y='wbdo')
plt.show()

sns.scatterplot(data=data, x='wbdo', y='wco')
plt.show()

sns.scatterplot(data=data, x='wec', y='wna')
plt.show()

data.hist(figsize=(17,17))
plt.show()

from sklearn.preprocessing import LabelEncoder

le=LabelEncoder()

data.location=le.fit_transform(data. location)
data.state=le.fit_transform(data.state)
data.head()

plt.figure(figsize=(20,20))
sns.heatmap(data.corr(), annot=True)
plt.show()

df=data.drop(['nco', 'npH', 'ndo', 'nbdo', 'nec', 'nna', 'location', 'state', 'station', 'wph', 'wdo', 'wbdo', 'wec', 'wna', 'wco', 'Temp'], axis=1)

df

df.to_csv('df')

df.corr().wqi.sort_values (ascending=False)

"""Splitting Dependent and Independent Columns"""

data.drop(['location', 'station', 'state'], axis =1, inplace=True)

data.head()

x=df.iloc[:,0:7].values

x.shape

y=df.iloc[:, -1:].values

y.shape

print(x)

print(y)

"""Splitting the Data into Train and Test"""

from sklearn.model_selection import train_test_split
x_train,x_test,y_train, y_test = train_test_split(x,y, test_size = 0.2, random_state=10)

#Feature Scaling
#from sklearn.preprocessing import StandardScaler
#sc = StandardScaler()
#x_train = sc.fit_transform(x_train)
#x_test sc. transform(x_test)

from sklearn.ensemble import RandomForestRegressor
regressor = RandomForestRegressor (n_estimators = 10, random_state = 0)
regressor.fit(x_train, y_train)
y_pred=regressor.predict(x_test)

"""Model Evaluation"""

from sklearn import metrics
print('MAE:',metrics.mean_absolute_error(y_test,y_pred))
print('MSE:',metrics.mean_squared_error(y_test,y_pred))
print('RMSE:',np.sqrt(metrics.mean_squared_error(y_test,y_pred)))

metrics.r2_score(y_test, y_pred)

regressor.predict([[5.7,7.2,189.0, 2.000000, 0.200000, 8391.0, 2014 ] ])

regressor.predict([[6.7,7.5,203.0,6.940049, 0.1, 27.0, 2014]])

import pickle

pickle.dump(regressor,open('model.pkl','wb'))
model=pickle.load(open('model.pkl','rb'))